{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with Autogen using Azure AI Services\n",
    "\n",
    "This notebook demonstrates implementing Retrieval-Augmented Generation (RAG) using Autogen agents with enhanced evaluation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the OS module to access environment variables like API keys\n",
    "import os\n",
    "# Import time module to measure processing and evaluation times\n",
    "import time\n",
    "# Import asyncio for asynchronous programming with async/await patterns\n",
    "import asyncio\n",
    "# Import typing hints for better code documentation and IDE support\n",
    "from typing import List, Dict\n",
    "\n",
    "# Import the AssistantAgent class from autogen_agentchat - this is our main AI agent\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "# Import CancellationToken to handle operation cancellation in async operations\n",
    "from autogen_core import CancellationToken\n",
    "# Import TextMessage to create message objects for agent communication\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "# Import Azure credential handling for secure authentication\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "# Import the Azure AI Chat Completion Client for OpenAI model interactions\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "\n",
    "# Import SearchClient to perform search operations on Azure AI Search index\n",
    "from azure.search.documents import SearchClient\n",
    "# Import SearchIndexClient to create and manage search indexes\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "# Import model classes to define the structure of our search index\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "\n",
    "# Import dotenv to load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file into the current environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "# Import the entire azure search models module for debugging purposes\n",
    "import azure.search.documents.indexes.models as azure_module\n",
    "# Print the type of SearchableField class to verify it's properly imported\n",
    "print(type(azure_module.SearchableField))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Client \n",
    "\n",
    "First, we initialize the Azure AI Chat Completion Client. This client will be used to interact with the Azure OpenAI service to generate responses to user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import autogen_ext.models.azure as M\n",
    "\n",
    "#help(M.AzureAIChatCompletionClient)\n",
    "\n",
    "#print(M.AzureAIChatCompletionClient.__doc__)\n",
    "\n",
    "#  |  Args:\n",
    "#  |      endpoint (str): The endpoint to use. **Required.**\n",
    "#  |      credential (union, AzureKeyCredential, AsyncTokenCredential): The credentials to use. **Required**\n",
    "#  |      model_info (ModelInfo): The model family and capabilities of the model. **Required.**\n",
    "#  |      model (str): The name of the model. **Required if model is hosted on GitHub Models.**\n",
    "#  |      frequency_penalty: (optional,float)\n",
    "#  |      presence_penalty: (optional,float)\n",
    "#  |      temperature: (optional,float)\n",
    "#  |      top_p: (optional,float)\n",
    "#  |      max_tokens: (optional,int)\n",
    "#  |      response_format: (optional, literal[\"text\", \"json_object\"])\n",
    "#  |      stop: (optional,List[str])\n",
    "#  |      tools: (optional,List[ChatCompletionsToolDefinition])\n",
    "#  |      tool_choice: (optional,Union[str, ChatCompletionsToolChoicePreset, ChatCompletionsNamedToolChoice]])\n",
    "#  |      seed: (optional,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Azure AI Chat Completion Client to interact with the GPT model\n",
    "client = AzureAIChatCompletionClient(\n",
    "    # Specify the model to use - gpt-4o-mini is a cost-effective version of GPT-4\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # Set the endpoint URL for Azure's model inference service\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # Use GitHub token for authentication (stored in environment variable)\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    # Define model capabilities for the client to understand what features are available\n",
    "    model_info={\n",
    "        # Model can output structured JSON responses\n",
    "        \"json_output\": True,\n",
    "        # Model supports function calling capabilities\n",
    "        \"function_calling\": True,\n",
    "        # Model can process and understand images\n",
    "        \"vision\": True,\n",
    "        # Set family as unknown since this is a custom configuration\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database Initialization\n",
    "\n",
    "We initialize Azure AI Search with persistent storage and add enhanced sample documents. Azure AI Search will be used to store and retrieve documents that provide context for generating accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure AI Search with persistent storage\n",
    "# Get the Azure Search service endpoint URL from environment variables\n",
    "search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "# Get the API key for Azure Search authentication from environment variables\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "# Define the name of our search index that will store travel documents\n",
    "index_name = \"travel-documents\"\n",
    "\n",
    "# Create a SearchClient to perform search operations on our index\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Create a SearchIndexClient to manage the search index structure\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Define the index schema - this determines what fields our documents will have\n",
    "fields = [\n",
    "    # Define 'id' field as a simple string that serves as the primary key\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    # Define 'content' field as searchable text that can be queried\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String)\n",
    "]\n",
    "\n",
    "# Create a SearchIndex object with our defined schema\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "# Create the actual index in Azure Search service\n",
    "index_client.create_index(index)\n",
    "\n",
    "# Enhanced sample documents - these represent our knowledge base\n",
    "documents = [\n",
    "    # Document about Contoso's luxury travel services\n",
    "    {\"id\": \"1\", \"content\": \"Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\"},\n",
    "    # Document about premium travel features\n",
    "    {\"id\": \"2\", \"content\": \"Our premium travel services include personalized itinerary planning and 24/7 concierge support.\"},\n",
    "    # Document about travel insurance coverage\n",
    "    {\"id\": \"3\", \"content\": \"Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\"},\n",
    "    # Document listing popular travel destinations\n",
    "    {\"id\": \"4\", \"content\": \"Popular destinations include the Maldives, Swiss Alps, and African safaris.\"},\n",
    "    # Document about exclusive travel experiences\n",
    "    {\"id\": \"5\", \"content\": \"Contoso Travel provides exclusive access to boutique hotels and private guided tours.\"}\n",
    "]\n",
    "\n",
    "# Upload all documents to the search index for retrieval\n",
    "search_client.upload_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_context(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs semantic search on the Azure AI Search index to find relevant documents.\n",
    "    Args:\n",
    "        query: The user's search query\n",
    "    Returns:\n",
    "        Formatted string containing all relevant document content\n",
    "    \"\"\"\n",
    "    # Execute search query against the Azure Search index\n",
    "    results = search_client.search(query)\n",
    "    # Initialize list to store formatted results\n",
    "    context_strings = []\n",
    "    # Iterate through search results and format each document\n",
    "    for result in results:\n",
    "        context_strings.append(f\"Document: {result['content']}\")\n",
    "    # Join all results with double newlines, or return \"No results found\" if empty\n",
    "    return \"\\n\\n\".join(context_strings) if context_strings else \"No results found\"\n",
    "\n",
    "def get_weather_data(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates retrieving weather data for a given location.\n",
    "    In a real-world scenario, this would call a weather API.\n",
    "    Args:\n",
    "        location: The city/location to get weather for\n",
    "    Returns:\n",
    "        Formatted weather information string\n",
    "    \"\"\"\n",
    "    # Simulated weather database - in production this would be an API call\n",
    "    weather_database = {\n",
    "        # Weather data for New York with temperature, condition, humidity, and wind\n",
    "        \"new york\": {\"temperature\": 72, \"condition\": \"Partly Cloudy\", \"humidity\": 65, \"wind\": \"10 mph\"},\n",
    "        # Weather data for London with rainy conditions\n",
    "        \"london\": {\"temperature\": 60, \"condition\": \"Rainy\", \"humidity\": 80, \"wind\": \"15 mph\"},\n",
    "        # Weather data for Tokyo with sunny conditions\n",
    "        \"tokyo\": {\"temperature\": 75, \"condition\": \"Sunny\", \"humidity\": 50, \"wind\": \"5 mph\"},\n",
    "        # Weather data for Sydney with clear skies\n",
    "        \"sydney\": {\"temperature\": 80, \"condition\": \"Clear\", \"humidity\": 45, \"wind\": \"12 mph\"},\n",
    "        # Weather data for Paris with cloudy conditions\n",
    "        \"paris\": {\"temperature\": 68, \"condition\": \"Cloudy\", \"humidity\": 70, \"wind\": \"8 mph\"},\n",
    "    }\n",
    "    \n",
    "    # Convert location to lowercase for consistent lookup\n",
    "    location_key = location.lower()\n",
    "    \n",
    "    # Check if we have weather data for the requested location\n",
    "    if location_key in weather_database:\n",
    "        # Extract weather data for the location\n",
    "        data = weather_database[location_key]\n",
    "        # Return formatted weather information string\n",
    "        return f\"Weather for {location.title()}:\\n\" \\\n",
    "               f\"Temperature: {data['temperature']}°F\\n\" \\\n",
    "               f\"Condition: {data['condition']}\\n\" \\\n",
    "               f\"Humidity: {data['humidity']}%\\n\" \\\n",
    "               f\"Wind: {data['wind']}\"\n",
    "    else:\n",
    "        # Return message if no data available for the location\n",
    "        return f\"No weather data available for {location}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "We configure the retrieval and assistant agents. The retrieval agent is specialized in finding relevant information using semantic search, while the assistant generates detailed responses based on the retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with enhanced capabilities\n",
    "# Initialize the main assistant agent that will generate responses\n",
    "assistant = AssistantAgent(\n",
    "    # Give the agent a descriptive name for identification\n",
    "    name=\"assistant\",\n",
    "    # Connect the agent to our Azure AI Chat Completion client\n",
    "    model_client=client,\n",
    "    # Define the system message that instructs the agent's behavior\n",
    "    system_message=(\n",
    "        \"You are a helpful AI assistant that provides answers using ONLY the provided context. \"\n",
    "        \"Do NOT include any external information. Base your answer entirely on the context given below.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGEvaluator Class\n",
    "\n",
    "We define the `RAGEvaluator` class to evaluate the response based on various metrics like response length, source citations, response time, and context relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    \"\"\"\n",
    "    A class to evaluate the quality and performance of RAG (Retrieval-Augmented Generation) responses.\n",
    "    Tracks various metrics to assess how well the system is performing.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize empty list to store all response evaluations for analysis\n",
    "        self.responses: List[Dict] = []\n",
    "\n",
    "    def evaluate_response(self, query: str, response: str, context: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluates a RAG response against multiple quality metrics.\n",
    "        Args:\n",
    "            query: The original user query\n",
    "            response: The generated response from the AI\n",
    "            context: List of documents that were used as context\n",
    "        Returns:\n",
    "            Dictionary containing various evaluation metrics\n",
    "        \"\"\"\n",
    "        # Record start time to measure evaluation performance\n",
    "        start_time = time.time()\n",
    "        # Calculate various quality metrics for the response\n",
    "        metrics = {\n",
    "            # Measure response length to assess verbosity\n",
    "            'response_length': len(response),\n",
    "            # Count how many source documents are actually cited in the response\n",
    "            'source_citations': sum(1 for doc in context if doc[\"content\"] in response),\n",
    "            # Measure how long the evaluation process takes\n",
    "            'evaluation_time': time.time() - start_time,\n",
    "            # Calculate relevance score between query and available context\n",
    "            'context_relevance': self._calculate_relevance(query, context)\n",
    "        }\n",
    "        # Store the evaluation data for later analysis\n",
    "        self.responses.append({\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        # Return the calculated metrics\n",
    "        return metrics\n",
    "\n",
    "    def _calculate_relevance(self, query: str, context: List[Dict]) -> float:\n",
    "        \"\"\"\n",
    "        Calculates a simple relevance score between the query and context documents.\n",
    "        Args:\n",
    "            query: The user's query\n",
    "            context: List of context documents\n",
    "        Returns:\n",
    "            Float between 0 and 1 representing relevance score\n",
    "        \"\"\"\n",
    "        # Count how many documents contain query terms (case-insensitive)\n",
    "        # Divide by total documents to get a percentage score\n",
    "        return sum(1 for c in context if query.lower() in c[\"content\"].lower()) / len(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Processing with RAG\n",
    "\n",
    "We define the `ask_rag` function to send the query to the assistant, process the response, and evaluate it. This function handles the interaction with the assistant and uses the evaluator to measure the quality of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_unified_rag(query: str, evaluator: RAGEvaluator, location: str = None):\n",
    "    \"\"\"\n",
    "    A unified RAG function that combines both document retrieval and weather data\n",
    "    based on the query and optional location parameter.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        evaluator: The RAG evaluator to measure response quality\n",
    "        location: Optional location for weather queries\n",
    "    Returns:\n",
    "        Dictionary containing response, metrics, and processing information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get context from both sources\n",
    "        # Retrieve relevant documents from Azure Search based on the query\n",
    "        retrieval_context = get_retrieval_context(query)\n",
    "        \n",
    "        # If location is provided, add weather data\n",
    "        weather_context = \"\"\n",
    "        if location:\n",
    "            # Get current weather data for the specified location\n",
    "            weather_context = get_weather_data(location)\n",
    "            # Create a header for weather information section\n",
    "            weather_intro = f\"\\nWeather Information for {location}:\\n\"\n",
    "        else:\n",
    "            # No weather intro if no location specified\n",
    "            weather_intro = \"\"\n",
    "        \n",
    "        # Augment the query with both contexts if available\n",
    "        # Combine retrieved documents and weather data into a comprehensive context\n",
    "        augmented_query = (\n",
    "            f\"Retrieved Context:\\n{retrieval_context}\\n\\n\"\n",
    "            f\"{weather_intro}{weather_context}\\n\\n\"\n",
    "            f\"User Query: {query}\\n\\n\"\n",
    "            \"Based ONLY on the above context, please provide the answer.\"\n",
    "        )\n",
    "\n",
    "        # Send the augmented query as a user message\n",
    "        # Record start time to measure response generation time\n",
    "        start_time = time.time()\n",
    "        # Send the augmented query to the assistant agent\n",
    "        response = await assistant.on_messages(\n",
    "            [TextMessage(content=augmented_query, source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "        # Calculate how long it took to generate the response\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        # Create combined context for evaluation\n",
    "        # Start with the existing travel documents\n",
    "        combined_context = documents.copy()\n",
    "        \n",
    "        # Add weather as a document if it exists\n",
    "        if location and weather_context:\n",
    "            # Add weather data as a pseudo-document for evaluation purposes\n",
    "            combined_context.append({\"id\": f\"weather-{location}\", \"content\": weather_context})\n",
    "        \n",
    "        # Evaluate the response using our RAG evaluator\n",
    "        metrics = evaluator.evaluate_response(\n",
    "            query=query,\n",
    "            response=response.chat_message.content,\n",
    "            context=combined_context\n",
    "        )\n",
    "        \n",
    "        # Package the results into a comprehensive response object\n",
    "        result = {\n",
    "            'response': response.chat_message.content,\n",
    "            'processing_time': processing_time,\n",
    "            'metrics': metrics,\n",
    "        }\n",
    "        \n",
    "        # Add location to result if provided for tracking purposes\n",
    "        if location:\n",
    "            result['location'] = location\n",
    "            \n",
    "        # Return the complete result package\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during processing\n",
    "        print(f\"Error processing unified query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "We initialize the evaluator and define the queries that we want to process and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    Main function that demonstrates the unified RAG system with different types of queries.\n",
    "    Tests travel-only, weather-only, and combined queries to show system versatility.\n",
    "    \"\"\"\n",
    "    # Initialize the RAG evaluator to track response quality\n",
    "    evaluator = RAGEvaluator()\n",
    "    \n",
    "    # Define user queries similar to the Semantic Kernel example\n",
    "    # Test different types of queries to demonstrate system capabilities\n",
    "    user_inputs = [\n",
    "        # Travel-only queries - tests document retrieval functionality\n",
    "        {\"query\": \"Can you explain Contoso's travel insurance coverage?\"},\n",
    "        \n",
    "        # Weather-only queries - tests weather data integration\n",
    "        {\"query\": \"What's the current weather condition in London?\", \"location\": \"london\"},\n",
    "        \n",
    "        # Combined queries - tests integration of both data sources\n",
    "        {\"query\": \"What is a good cold destination offered by Contoso and what is its temperature?\", \"location\": \"london\"},\n",
    "    ]\n",
    "    \n",
    "    # Print header for the demo\n",
    "    print(\"Processing Queries:\")\n",
    "    # Process each query in the test set\n",
    "    for query_data in user_inputs:\n",
    "        # Extract the query text from the query data\n",
    "        query = query_data[\"query\"]\n",
    "        # Extract location if specified (None if not present)\n",
    "        location = query_data.get(\"location\")\n",
    "        \n",
    "        # Print different headers based on whether location is specified\n",
    "        if location:\n",
    "            print(f\"\\nProcessing Query for {location}: {query}\")\n",
    "        else:\n",
    "            print(f\"\\nProcessing Query: {query}\")\n",
    "        \n",
    "        # Get the RAG context for printing (similar to the Semantic Kernel example)\n",
    "        # Retrieve documents relevant to the query for transparency\n",
    "        retrieval_context = get_retrieval_context(query)\n",
    "        # Get weather data if location is specified\n",
    "        weather_context = get_weather_data(location) if location else \"\"\n",
    "        \n",
    "        # Print the RAG context for transparency - show user what data is being used\n",
    "        print(\"\\n--- RAG Context ---\")\n",
    "        print(retrieval_context)\n",
    "        if weather_context:\n",
    "            print(f\"\\n--- Weather Context for {location} ---\")\n",
    "            print(weather_context)\n",
    "        print(\"-------------------\\n\")\n",
    "            \n",
    "        # Process the query through our unified RAG system\n",
    "        result = await ask_unified_rag(query, evaluator, location)\n",
    "        # Display results if processing was successful\n",
    "        if result:\n",
    "            print(\"Response:\", result['response'])\n",
    "            print(\"\\nMetrics:\", result['metrics'])\n",
    "        # Print separator between queries for readability\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Script\n",
    "\n",
    "We check if the script is running in an interactive environment or a standard script, and run the main function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Queries:\n",
      "\n",
      "Processing Query: Can you explain Contoso's travel insurance coverage?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "Document: Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\n",
      "\n",
      "Document: Our premium travel services include personalized itinerary planning and 24/7 concierge support.\n",
      "\n",
      "Document: Contoso Travel provides exclusive access to boutique hotels and private guided tours.\n",
      "-------------------\n",
      "\n",
      "Response: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "Metrics: {'response_length': 92, 'source_citations': 1, 'evaluation_time': 8.106231689453125e-06, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Processing Query for london: What's the current weather condition in London?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Popular destinations include the Maldives, Swiss Alps, and African safaris.\n",
      "\n",
      "--- Weather Context for london ---\n",
      "Weather for London:\n",
      "Temperature: 60°F\n",
      "Condition: Rainy\n",
      "Humidity: 80%\n",
      "Wind: 15 mph\n",
      "-------------------\n",
      "\n",
      "Response: The current weather condition in London is rainy.\n",
      "\n",
      "Metrics: {'response_length': 49, 'source_citations': 0, 'evaluation_time': 8.344650268554688e-06, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Processing Query for london: What is a good cold destination offered by Contoso and what is its temperature?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Contoso Travel provides exclusive access to boutique hotels and private guided tours.\n",
      "\n",
      "Document: Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\n",
      "\n",
      "Document: Popular destinations include the Maldives, Swiss Alps, and African safaris.\n",
      "\n",
      "Document: Our premium travel services include personalized itinerary planning and 24/7 concierge support.\n",
      "\n",
      "Document: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "--- Weather Context for london ---\n",
      "Weather for London:\n",
      "Temperature: 60°F\n",
      "Condition: Rainy\n",
      "Humidity: 80%\n",
      "Wind: 15 mph\n",
      "-------------------\n",
      "\n",
      "Response: A good cold destination offered by Contoso is the Swiss Alps. However, the context does not provide a specific temperature for that destination.\n",
      "\n",
      "Metrics: {'response_length': 144, 'source_citations': 0, 'evaluation_time': 7.3909759521484375e-06, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if this script is being run directly (not imported as a module)\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if we're already in an async event loop (like in Jupyter notebooks)\n",
    "    if asyncio.get_event_loop().is_running():\n",
    "        # If in an existing loop, await the main function directly\n",
    "        await main()\n",
    "    else:\n",
    "        # If not in a loop, create a new event loop and run main function\n",
    "        asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
